{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import efficientnet.tfkeras as efn \n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ImageDataAugmentor.image_data_augmentor import *\n",
    "from albumentations import (Compose, GaussNoise, Blur, \n",
    "                            Affine, Perspective,Sharpen, Superpixels,\n",
    "                            CenterCrop, ChannelDropout, ChannelShuffle, \n",
    "                            CLAHE, CoarseDropout, Downscale, \n",
    "                            ElasticTransform, Equalize, FancyPCA, \n",
    "                            Flip, GaussianBlur, GlassBlur, \n",
    "                            GridDistortion, GridDropout, Posterize, \n",
    "                            RandomBrightness, RandomContrast, RandomFog, #RandomBrightnessContrast,\n",
    "                            RandomGamma, \n",
    "                            RandomGridShuffle, #RandomRain, RandomShow, Transpose\n",
    "                            RandomShadow, RandomRotate90, #RandomResizedCrop\n",
    "                            \n",
    "                            VerticalFlip, HorizontalFlip, RandomBrightness, RandomContrast, \n",
    "                            OpticalDistortion, HueSaturationValue, ShiftScaleRotate, Cutout, OneOf,\n",
    "                            ColorJitter\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Read in the CSV files that provide information on the images. \n",
    "Set path that will be used to locate the files.  \n",
    "'''\n",
    "\n",
    "## The ISIC 2020 Training Images\n",
    "train_dir = '/home/mikylab/cycleGan/melanomaImages/train/'\n",
    "train_csv = pd.read_csv('/home/mikylab/test2train/csv_files/train.csv')\n",
    "\n",
    "\n",
    "## The ISIC 2016 Training Images to be used as a test set \n",
    "test_dir_16 = '/home/mikylab/cycleGan/2016_test_data/'\n",
    "test_csv_16 = pd.read_csv('/home/mikylab/test2train/csv_files/ISBI2016_GroundTruth.csv')\n",
    "\n",
    "## The ISIC 2017 Training Images to be used as a test set \n",
    "test_dir_17 = '/home/mikylab/cycleGan/ISIC-2017_TestData/'\n",
    "test_csv_17 = pd.read_csv('/home/mikylab/test2train/csv_files/ISIC-2017_Test_GroundTruth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the number of the benign and malignant images in the original training set\n",
    "neg, pos = np.bincount(train_csv['target'])\n",
    "total = neg + pos\n",
    "print('Melanoma Classification:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample a subset of benign images to mitigate the class imbalance\n",
    "mal_train = train_csv[train_csv['target']==1]\n",
    "ben_train = train_csv[train_csv['target']==0].sample(n=2000, random_state = 316)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine benign and malignant image subsets for training and add .jpg to the files' names\n",
    "train_data =  pd.concat([mal_train, ben_train], ignore_index=True, sort =False)\n",
    "train_data['image_name'] = train_data['image_name'] + '.jpg'\n",
    "\n",
    "\n",
    "## Remove unnecessary columns\n",
    "train_data = train_data.drop(['patient_id', 'sex', 'age_approx', 'anatom_site_general_challenge', 'diagnosis', 'benign_malignant'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjust the CSV for the two test sets\n",
    "test_data_16 = pd.DataFrame({'image_dir': test_csv_16['ISIC_0000003'], 'target': test_csv_16['0.0']})\n",
    "test_data_16['image_dir'] = test_data_16['image_dir'] + '.jpg'\n",
    "\n",
    "test_data_17 = pd.DataFrame({'image_dir': test_csv_17['image_id'], 'target': test_csv_17['melanoma']})\n",
    "test_data_17['image_dir'] = test_data_17['image_dir'] + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the number of the benign and malignant images in the adjusted training set\n",
    "\n",
    "neg, pos = np.bincount(train_data['target'])\n",
    "total = neg + pos\n",
    "print('Melanoma Classification:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the training set into training and validation sets\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_data['image_name'], train_data['target'], test_size = 0.20, shuffle = True, random_state = 316)\n",
    "train_gen = pd.DataFrame({'image_dir': x_train, 'target': y_train})\n",
    "val_gen = pd.DataFrame({'image_dir': x_val, 'target': y_val})\n",
    "\n",
    "train_gen['target'].astype(dtype = 'int16')\n",
    "val_gen['target'].astype(dtype = 'int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count how many benign and malignant images are in each set. \n",
    "\n",
    "''' \n",
    "train_gen[train_gen['target'] == 1].shape\n",
    "val_gen[val_gen['target'] == 1].shape\n",
    "train_gen[train_gen['target'] == 0].shape\n",
    "\n",
    "train_gen.to_csv('CNN_trainset.csv', index = False)\n",
    "val_gen.to_csv('CNN_valset.csv', index = False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate a weight for each class to mitagate the class imbalance\n",
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional augmentations from the https://albumentations.ai library\n",
    "\n",
    "AUGMENTATIONS = Compose([\n",
    "                        VerticalFlip(p =.5), \n",
    "                        HorizontalFlip(p =.5),\n",
    "                        RandomBrightness(p = .5), \n",
    "                        RandomContrast(p =.5), \n",
    "                        OneOf([\n",
    "                            OpticalDistortion(distort_limit =1.0), \n",
    "                            GridDistortion(num_steps=5, distort_limit = 1.), \n",
    "                            ElasticTransform(alpha=3),\n",
    "                        ]),\n",
    "                        CLAHE(clip_limit=4.0, p=0.7), \n",
    "                        HueSaturationValue(hue_shift_limit = 10, sat_shift_limit= 20, val_shift_limit = 10, p = .5), \n",
    "                        ShiftScaleRotate (shift_limit = 0.2, scale_limit = 0.1, rotate_limit = 15, border_mode = 0, p = .85), \n",
    "                        Cutout(max_h_size = int(256*.375), max_w_size = int(256*.375), num_holes =1, p = 0.7), \n",
    "                        \n",
    "                        Affine(scale = [0.7, 1.3],  translate_percent = .25, rotate = [-360, 360], shear = [0, 20]),\n",
    "                        ColorJitter(brightness=[0.9, 1.1], contrast=[0.9, 1.1], saturation=[0.9, 1.1], hue=[0, .2], always_apply=False, p=0.5)\n",
    "    \n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ImageDataAugmentor from https://github.com/mjkvaak/ImageDataAugmentor, used to allow the Albumentations library\n",
    "\n",
    "train_image_gen = ImageDataAugmentor(rescale=1./255,\n",
    "                                     augment = AUGMENTATIONS\n",
    "                                    )\n",
    "test_image_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creation of the image generator datasets, images resized to (256, 256) and batch set to 1. \n",
    "\n",
    "Train_Data = train_image_gen.flow_from_dataframe(dataframe = train_gen,\n",
    "                                              directory = train_dir,\n",
    "                                              x_col = 'image_dir', \n",
    "                                              y_col = 'target', \n",
    "                                              class_mode = 'raw', \n",
    "                                              target_size = (256, 256),\n",
    "                                              color_mode = 'rgb', \n",
    "                                              batch_size = 1, \n",
    "                                              seed = 316, \n",
    "                                              shuffle = True,\n",
    "                                    )\n",
    "\n",
    "Val_Data = test_image_gen.flow_from_dataframe(dataframe = val_gen,\n",
    "                                              directory = train_dir,\n",
    "                                              x_col = 'image_dir', \n",
    "                                              y_col = 'target', \n",
    "                                              class_mode = 'raw',\n",
    "                                              target_size = (256, 256),\n",
    "                                              color_mode = 'rgb', \n",
    "                                              batch_size = 1, \n",
    "                                              seed = 316, \n",
    "                                              shuffle = True,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data_16 = test_image_gen.flow_from_dataframe(dataframe = test_data_16, \n",
    "                                              directory = test_dir_16, \n",
    "                                              x_col = 'image_dir', \n",
    "                                              y_col = 'target', \n",
    "                                              class_mode = 'raw',\n",
    "                                              target_size = (256, 256),\n",
    "                                              color_mode = 'rgb', \n",
    "                                              batch_size = 1, \n",
    "                                              seed = 316, \n",
    "                                              shuffle = False,\n",
    "                                              )\n",
    "\n",
    "Test_Data_17 = test_image_gen.flow_from_dataframe(dataframe = test_data_17, \n",
    "                                              directory = test_dir_17, \n",
    "                                              x_col = 'image_dir', \n",
    "                                              y_col = 'target', \n",
    "                                              class_mode = 'raw',\n",
    "                                              target_size = (256, 256),\n",
    "                                              color_mode = 'rgb', \n",
    "                                              batch_size = 1, \n",
    "                                              seed = 316, \n",
    "                                              shuffle = False,\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the CNN model from the tf.keras EfficientNetB3 that was originally trained on the imagenet dataset\n",
    "def create_model():  \n",
    "    enb3 = tf.keras.applications.EfficientNetB3(weights=\"imagenet\", include_top=False, input_shape=(256, 256, 3), pooling = 'avg')\n",
    "    x = tf.keras.layers.Flatten()(enb3.output)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = tf.keras.Model(enb3.input, output)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the initial learning rate and the learning rate scheduler\n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile the model using AUC as the metric \n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 1e-5 )\n",
    "model.compile(loss='binary_crossentropy', metrics=tf.keras.metrics.AUC(name=\"auc\"),optimizer=opt)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 100, verbose = 1, restore_best_weights = True)\n",
    "cb = early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Use of class weight is optional. \n",
    "\n",
    "history = model.fit(\n",
    "    Train_Data,\n",
    "    steps_per_epoch= 300,\n",
    "    epochs= 400,\n",
    "    validation_data=Val_Data,\n",
    "    callbacks=cb,\n",
    "    #class_weight = class_weight,\n",
    "    validation_steps= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the model metrics from training\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "plt.title('model auc')\n",
    "plt.ylabel('auc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_melanoma_weights_full_7.1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate or predict the model's performance on Val_Data, Test_Data_17 or Test_Data_16 datasets\n",
    "model.evaluate(Test_Data_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample a single image and use the CNN to make a classification prediction\n",
    "def image_pred(data):\n",
    "    train_img, train_class = data.next()\n",
    "    train_img = train_img[0,:, :]\n",
    "    img_array = tf.expand_dims(train_img, axis=0)\n",
    "    plt.imshow(train_img)\n",
    "    plt.title(' Truth: ' + str(train_class)+ \" Pred: \" + str(model.predict(img_array)[0]))\n",
    "    \n",
    "image_pred(Test_Data_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a pretained model \n",
    "load_model = tf.keras.models.load_model('cnn_melanoma_new_aug_7.1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile the model with additional metrics. \n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "      tf.keras.metrics.SpecificityAtSensitivity(.82)\n",
    "]\n",
    "\n",
    "load_model.compile(loss='binary_crossentropy', metrics=METRICS,optimizer=opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the ROC curve\n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the classes on the datasets' images \n",
    "predicted_labels_test = model.predict(Test_Data_16).squeeze()\n",
    "true_labels_test =test_data_16['target'].to_numpy().reshape(378,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_test_17 = model.predict(Test_Data_17).squeeze()\n",
    "true_labels_test_17 =test_data_17['target'].to_numpy().reshape(600,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_val = model.predict(Val_Data).squeeze()\n",
    "true_labels_val =val_gen['target'].to_numpy().reshape(517,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plot_roc(\"Val Baseline\", true_labels_val, predicted_labels_val, color=colors[0], linestyle='--')\n",
    "plot_roc(\"Test_2016 Baseline\", true_labels_test, predicted_labels_test, color=colors[1])\n",
    "plot_roc(\"Test_2017 Baseline\", true_labels_test_17, predicted_labels_test_17, color=colors[2])\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
